{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ES19BTECH11017_CS19BTECH11051_Assgn5.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ksp9BQQa8omL"},"outputs":[],"source":["import numpy as np\n","import pandas as pd \n","import warnings\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import mean_squared_error"]},{"cell_type":"code","source":["def sigmoid(x):\n","    return 1.0/(1 + np.exp(-1*x))\n","\n","def lossFunction(y, y_predicted):\n","    C_tp = 0.5\n","    C_tn = 0.5\n","    C_fn = 10\n","    C_fp = 10\n","    loss = np.mean(y*((np.log(y_predicted)*C_tp) + ((1 - np.log(y_predicted))*C_fn)) + (1 - y)*((np.log(1 - y_predicted)*C_tn) +(np.log(y_predicted)*C_fp)))\n","\n","    loss = -1*loss\n","    return loss\n","\n","\n","def predict(X, w, b):\n","    return sigmoid(np.dot(X, w) + b)  \n","\n","\n","def gradients(X, y, y_predicted):\n","    Y = np.zeros((y.shape[0], 1))\n","    \n","    for i in range(y.shape[0]):\n","      Y[i][0] = y_predicted[i] - y[i]\n","\n","    dw = np.dot(X.T, Y)\n","    db = np.sum((y_predicted - y)) \n","    return dw, db\n","\n","\n","def weightInitialization(n_features):\n","    w = np.full((n_features, 1), 0.5)\n","    b = 0\n","    return w,b\n","\n","\n","def train(X, y, w, b, epochs = 1000, gamma = 0.1, minLoss = 0.001):\n","    \n","    y_predicted = predict(X, w, b)\n","    loss = lossFunction(y, y_predicted)\n","\n","    for i in range(epochs):\n","      dw, db = gradients(X, y, y_predicted)\n","      w = w - gamma*dw\n","      b = b - gamma*db\n","      y_predicted = predict(X, w, b)\n","      prevLoss = loss\n","      loss = lossFunction(y, y_predicted)\n","\n","      if(prevLoss - loss < minLoss):\n","        break\n","\n","    return w, b\n","\n","\n","def classify(X, w, b):\n","    y_predicted = predict(X, w, b)\n","    prediction = []\n","    prediction = [1 if i > 0.5 else 0 for i in y_predicted]\n","    return np.array(prediction)\n"],"metadata":{"id":"Ldy-BIEz89qq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\"data.csv\")"],"metadata":{"id":"eglLicz-89fv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#x: features of the data\n","#y: labels of the data\n","\n","y = df.iloc[:, 0]\n","y = y.to_numpy()\n","\n","x = df.drop(['Status'], axis = 1)\n","x = x.to_numpy()"],"metadata":{"id":"GiTnYlEmChk2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Splitting the given dataset to check how the model performs\n","\n","X_train, X_test, y_train, y_test = train_test_split(x[:1000], y[:1000], test_size=0.33, random_state=1)\n","w, b = weightInitialization(X_train.shape[1])\n","warnings.filterwarnings(\"ignore\")\n","w_final, b_final = train(X_train, y_train, w, b, epochs = 1000, gamma = 0.1, minLoss = 0.0001)\n","\n","\n","#Predicting the status for the test cases\n","predictions = classify(X_test, w_final, b_final)\n","\n","\n","#Evaluating the performance of the Cost Sensitive Logistic Regression Model\n","accuracy = accuracy_score(y_test, predictions)\n","precision = precision_score(y_test, predictions, average=None)[1]\n","recall = recall_score(y_test, predictions, average=None)[1]\n","\n","print(\"Test Set Accuracy: \", accuracy)\n","print(\"Test Set Precision: \", precision)\n","print(\"Test Set Recall: \", recall)"],"metadata":{"id":"wSFYTSQrClYu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dc1d7a64-c6d7-41d2-f471-b384b528d281"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Set Accuracy:  0.8303030303030303\n","Test Set Precision:  0.9044943820224719\n","Test Set Recall:  0.805\n"]}]}]}