{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ES19BTECH11017_Assign2","provenance":[{"file_id":"1Y3ThP9SWSlzZIWU0g4EhGnxgElCk_FLz","timestamp":1613735446560}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"61t4V-dD2rkP"},"source":["# Question 1\n","\n","We know that the margin vectors are given by:\n","\\begin{eqnarray}\n","  w \\cdot X + b = \\pm 1\\\\\n","\\end{eqnarray}\n","\n","On replacing $1$ with some constant $\\gamma$ we get:\n","\\begin{eqnarray}\n","  w \\cdot X + b = \\pm \\gamma\\\\\n","\\end{eqnarray}\n","On dividing the equation with $\\gamma$:\n","\\begin{eqnarray}\n","  \\frac {w}{\\gamma} \\cdot X + \\frac {b}{\\gamma} = \\pm 1\\\\\n","\\end{eqnarray}\n","\n","Since the goal of getting the hyperplane equation is minimising $||w||$, dividing $w$ by a scalar doesn't change anything, the equation of the hyper plane will still end up being $w \\cdot X + b = 0$. Hence, changing $1$ to another constant $\\gamma$ gives us the same solution.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MQ6kPYCF2uZn"},"source":["# Question 2\n","\n","To prove this equation we'll make use of the following two equations from class:\n","\n","$$\n","w = \\sum_{j} \\alpha_j y_j X_j\\\\\n","\\sum_{j} \\alpha_j y_j = 0\n","$$\n","\n","And given,\n","$$\n","\\rho = \\frac {1} {||w||}\\\\\n","\\frac {1} {\\rho} = ||w||\\\\\n","\\frac {1} {\\rho^2} = ||w||^2\n","$$\n","\n","\n","The equation of the margin vectors is $w^T x + b = \\pm 1$. If $X_i$ is a support vector and $y_i$ is its label, we can write  $w^T X_i + b = y_i$.\n","\n","On substituting:\n","\\begin{eqnarray}\n","  w^T X_i + b = y_i\\\\\n","  \\sum_{j} \\alpha_j y_j X_j^T X_i + b = y_i\n","\\end{eqnarray}\n","\n","Multiplying the equation with $\\alpha_i y_i$:\n","\\begin{eqnarray}\n","  \\sum_{j} \\alpha_j y_j X_j^T X_i \\alpha_i y_i + b \\alpha_i y_i = \\alpha_i y_i^2\n","\\end{eqnarray}\n","\n","On summing over $i$:\n","\\begin{eqnarray}\n","  \\sum_{i,j} \\alpha_j y_j X_j^T X_i \\alpha_i y_i + b \\sum_{i}\\alpha_i y_i = \\sum_{i}\\alpha_i y_i^2\\\\\n","  \\sum_{i,j} \\alpha_i\\alpha_j y_i y_j X_j^T X_i  + b \\sum_{i}\\alpha_i y_i = \\sum_{i}\\alpha_i y_i^2\n","\\end{eqnarray}\n","\n","Since $y_i$ lies on the margin vector, it equals $\\pm 1$ thus $y_i^2 = 1$. Using this and substituting values from the equations derived in class, we get:\n","\\begin{eqnarray}\n","  \\sum_{i,j} \\alpha_i\\alpha_j y_i y_j X_j^T X_i  + b \\sum_{i}\\alpha_i y_i &=& \\sum_{i}\\alpha_i y_i^2\\\\\n","  \\sum_{i,j} \\alpha_i\\alpha_j y_i y_j X_j^T X_i  + b \\times 0 &=& \\sum_{i}\\alpha_i\\\\ \n","  \\sum_{i,j} \\alpha_i\\alpha_j y_i y_j X_j^T X_i &=& \\sum_{i}\\alpha_i\\\\\n","  \\sum_{j} \\alpha_j y_j X_j^T \\times \\sum_{i} \\alpha_i y_i X_i &=& \\sum_{i}\\alpha_i\\\\\n","  w^T  w &=& \\sum_{i}\\alpha_i\\\\\n","  ||w||^2 &=& \\sum_{i}\\alpha_i\\\\\n","  \\frac 1 {\\rho^2} &=& \\sum_{i}\\alpha_i\n","\\end{eqnarray}\n","\n","Hence, proved.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vWsgR9G52vPL"},"source":["# Question 3"]},{"cell_type":"markdown","metadata":{"id":"8vjdomjFxkUe"},"source":["For this question, we will be using Mercer's condition to check the validity of the given functions.\n","\n","A kernel $K(x,z)$ is said to be valid if it satisfies Mercer's condition:\n","\\begin{eqnarray}\n","  \\iint f(x)K(x,z)f(z)\\,dx\\,dz \\geq 0\n","\\end{eqnarray}\n","\n","Since, $k_1$ and $k_2$ are valid kernels, we can write:\n","\\begin{eqnarray}\n","  \\iint f(x)k_1(x,z)f(z)\\,dx\\,dz \\geq 0\\\\\n","  \\iint f(x)k_2(x,z)f(z)\\,dx\\,dz \\geq 0\n","\\end{eqnarray}\n","\n","A kernel $K(x,z)$ can be written as:\n","\\begin{eqnarray}\n","K(x,z) &=& \\phi(x) \\cdot \\phi(z)\\\\\n","K(x,z) &=& \\sum_{i} \\phi_i(x)\\phi_i(z)\n","\\end{eqnarray}\n","\n","Thus,\n","\\begin{eqnarray}\n","k_1(x,z) &=& \\sum_{i} \\phi_i(x)^{(1)}\\phi_i(z)^{(1)}\\\\\n","k_2(x,z) &=& \\sum_{i} \\phi_i(x)^{(2)}\\phi_i(z)^{(2)}\n","\\end{eqnarray}"]},{"cell_type":"markdown","metadata":{"id":"BzvWUVmJ2ArE"},"source":["## (a)\n","\n","\\begin{eqnarray}\n","  k(x,z) = k_1(x,z) + k_2(x,z)\n","\\end{eqnarray}\n","\n","Substituting this in the Mercer's condition:\n","\\begin{eqnarray}\n","  \\iint f(x)k(x,z)f(z)\\,dx\\,dz &\\geq& 0\\\\\n","  \\iint f(x)(k_1(x,z) + k_2(x,z))f(z)\\,dx\\,dz &\\geq& 0\\\\\n","  \\iint f(x)k_1(x,z)f(z)\\,dx\\,dz + \\iint f(x)k_2(x,z)f(z)\\,dx\\,dz &\\geq& 0\n","\\end{eqnarray}\n","\n","Since both parts of the above sum are greater than zero, the final sum will also be greater that zero, thereby satisfying Mercer's condition. Hence, this function is a valid kernel."]},{"cell_type":"markdown","metadata":{"id":"zOfTEWvp4bGB"},"source":["## (b)\n","\n","\\begin{eqnarray}\n","  k(x,z) = k_1(x,z)k_2(x,z)\n","\\end{eqnarray}\n","\n","Substituting this and the dot product representations in the Mercer's condition:\n","\\begin{eqnarray}\n","  \\iint f(x)k(x,z)f(z)\\,dx\\,dz &=& \\iint f(x)k_1(x,z)k_2(x,z)f(z)\\,dx\\,dz\\\\ \n","  &=&\\iint f(x)\\left(\\sum_{i} \\phi_i(x)^{(1)}\\phi_i(z)^{(1)}\\right)\\left(\\sum_{i} \\phi_i(x)^{(2)}\\phi_i(z)^{(2)}\\right)f(z)\\,dx\\,dz \\\\\n","  &=&\\sum_{i} \\sum_{i} \\iint  \\phi_i(x)^{(1)} \\phi_i(x)^{(2)} f(x)\\,dx \\phi_i(z)^{(2)} \\phi_i(z)^{(1)} f(z) \\,dz \\\\\n","  &=& \\sum_{i}\\sum_{i}\\int  \\phi_i(x)^{(1)}\\phi_i(x)^{(2)}f(x)\\,dx\\int \\phi_i(z)^{(1)}\\phi_i(z)^{(2)}f(z)\\,dz \n","\\end{eqnarray}\n","\n","Since both, the integrals are of the same format, we can replace the variables $x$ and $z$ with another generic variable:\n","\\begin{eqnarray}\n","  &=&\\sum_{i}\\sum_{i}\\left[\\int \\phi_i(y)^{(1)}\\phi_i(y)^{(2)}f(y)\\,dy\\right]^2&\\geq& 0\\\\\n","\\end{eqnarray}\n","\n","A squared value is always greater than zero, and thus it satisfies a condition proving that the given function is a valid kernel."]},{"cell_type":"markdown","metadata":{"id":"fb2JSWUjR29q"},"source":["## (c)\n","\n","$k(x,z) = h(k_1(x,z))$ where h is a polynomial function with positive co-efficients.\n","\n","We know that the polynomial function is going to be of the following form:\n","\\begin{eqnarray}\n","  h(k(x,z)) = c_0 + c_1k(x,z) + c_2k(x,z)^2 + c_3k(x,z)^3 + . . . \n","\\end{eqnarray}\n","\n","Now, we can write $k(x,z)^2$ as $k(x,z)k(x,z)$ which is a valid kernel as proved in part (b). Similarly, all higher powers of $k(x,z)$ can be proved to be valid kernels in the same way.\n","\n","Moreover, a scalar multiplied with a kernel is also a valid kernel function since:\n","\\begin{eqnarray}\n","  C \\times k(x,z) = C \\iint f(x)k(x,z)f(z)\\,dx\\,dz\\\\\n","  C\\iint f(x)k(x,z)f(z)\\,dx\\,dz &\\geq& 0\\\\\n","\\end{eqnarray}\n","\n","Thus, by combining the proofs in (a) and (b), we can declare the function $h(k_1(x,z))$ as a valid kernel.\n"]},{"cell_type":"markdown","metadata":{"id":"1e2xiQz_Udsr"},"source":["## (d)\n","\n","\\begin{eqnarray}\n","  k(x,z) = exp(k(x,z))\n","\\end{eqnarray}\n","\n","We know that the Taylor expansion of the exponential function is the following:\n","\\begin{eqnarray}\n","  exp(k(x,z)) = 1 + \\frac {k(x,z)}{1!} + \\frac {k(x,z)^2}{2!} + \\frac {k(x,z)^3}{3!} +  . . . \n","\\end{eqnarray}\n","\n","On comparing this with the polynomial structure in part (c), we notice that both the expressions have the same structure, hence the expansion is a polynomial. And as the polynomial function is a valid kernel, so is the exponential function.\n"]},{"cell_type":"markdown","metadata":{"id":"auG_xrNBXcL6"},"source":["## (e)\n","\n","\\begin{eqnarray}\n","  k(x,z) = exp(\\frac {-||x - z||_2^2}{\\sigma^2})\n","\\end{eqnarray}\n","\n","On expanding the numerator (Eucledian distance) we get:\n","\\begin{eqnarray}\n","  exp(\\frac {-||x - z||_2^2}{\\sigma^2}) &=& exp(\\frac {- ||x||^2 + 2 x \\cdot z - ||z||^2 }{\\sigma^2})\\\\\n","  &=& exp(\\frac {-||x||^2}{\\sigma^2})exp(\\frac {2 x \\cdot z}{\\sigma^2})exp(\\frac {-||z||^2}{\\sigma^2})\n","\\end{eqnarray}\n","\n","The second term is the exponent of a kernel (dot product) and that is also a kernel according to part (d). The first and third terms are functions of $x$ and $z$.\n","\n","Thus, it can be rewritten as:\n","\\begin{eqnarray}\n","  exp(\\frac {-||x - z||_2^2}{\\sigma^2}) &=& exp(\\frac {-||x||^2}{\\sigma^2})exp(\\frac {2 x \\cdot z}{\\sigma^2})exp(\\frac {-||z||^2}{\\sigma^2})\\\\\n","  &=& g(x)exp(k'(x,z))g(z)\n","\\end{eqnarray}\n","\n","Now, on substituting the above equation into the Mercer's equation we get:\n","\\begin{eqnarray}\n","  \\iint f(x)k(x,z)f(z)\\,dx\\,dz &=& \\iint f(x)g(x)exp(k'(x,z))g(z)f(z)\\,dx\\,dz\\\\ \n","\\end{eqnarray} \n","\n","Writing $f(x)g(x)$ as $F(x)$, $f(z)g(z)$ as $F(z)$ $exp(k'(x,z))$ as $K(x,z)$ and we get:\n","\\begin{eqnarray}\n","  \\iint f(x)g(x)exp(k'(x,z))g(z)f(z)\\,dx\\,dz &=& \\iint F(x)K(x,z)F(z)\\,dx\\,dz\\\\ \n","\\end{eqnarray} \n","Which is in the same form as the Mercer equation's original format, thus:\n","\\begin{eqnarray}\n"," \\iint F(x)K(x,z)F(z)\\,dx\\,dz \\geq 0\\\\ \n","\\end{eqnarray} \n","\n","Thus, the given kernel functions is a valid one.\n"]},{"cell_type":"markdown","metadata":{"id":"f1xgoA0nhfoj"},"source":["# Question 4"]},{"cell_type":"markdown","metadata":{"id":"3A_FWn6khh2L"},"source":["## (a)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CwFJP6cqtqhB","executionInfo":{"status":"ok","timestamp":1633368228039,"user_tz":-330,"elapsed":348,"user":{"displayName":"SOUMI CHAKRABORTY","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09195013844947693927"}},"outputId":"d3c6432e-8bcf-43ca-b9d2-df5a0fff5295"},"source":["import csv\n","import numpy as np\n","from sklearn import svm\n","import sys\n","\n","# Enter You Name Here\n","myname = \"Soumi-Chakraborty\"\n","\n","def run_svm():\n","\n","    # Load data set\n","    # data_set_path_train = \"/content/drive/MyDrive/Acad_Stuff/Course Work/Semester 5/FoML/Ass2/features.train.txt\"\n","    # data_set_path_test = \"/content/drive/MyDrive/Acad_Stuff/Course Work/Semester 5/FoML/Ass2/features.test.txt\"\n","\n","    data_set_path_train = \"http://www.amlbook.com/data/zip/features.train\"\n","    data_set_path_test = \"http://www.amlbook.com/data/zip/features.test\"\n","    \n","    train_data = np.loadtxt(data_set_path_train)\n","    ones = np.where(train_data[:, 0] == 1)\n","    fives = np.where(train_data[:, 0] == 5)\n","    labels = np.append(ones, fives , axis=1)\n","    labels = np.sort(labels)\n","    train_data = (train_data[labels])[0]\n","    print(\"Number of training records: %d\" % len(train_data))\n","\n","    # test set\n","    test_data = np.loadtxt(data_set_path_test)\n","    ones = np.where(test_data[:, 0] == 1)\n","    fives = np.where(test_data[:, 0] == 5)\n","    labels = np.append(ones, fives , axis=1)\n","    labels = np.sort(labels)\n","    test_data = (test_data[labels])[0]\n","    print(\"Number of testing records: %d\" % len(test_data))\n","\n","    # training the classifier\n","    X = train_data[:, 1:] # all rows, all columns except the last\n","    y = train_data[:, 0]  # all rows, only the last column\n","    svc = svm.SVC(kernel ='linear')\n","    svc.fit(X, y)\n","\n","    X_test =  test_data[:, 1:] # all rows, all columns except the last\n","    y_test = test_data[:,0]  # all rows, only the last column\n","\n","    # predict results for test set\n","    predictions = svc.predict(X_test)\n","\n","\n","    # compute accuracy\n","    results = predictions == y_test\n","    accuracy = float(np.count_nonzero(results))/float(len(results))\n","    print(\"Accuracy on the test set: %.4f\" % accuracy)    \n","\n","    # number of support vectors\n","    sv_count = svc.n_support_\n","    print(\"Support vectors for each class:\", sv_count)\n","    print(\"Total number of support vectors:\", sv_count.sum())  \n","\n","\n","if __name__ == \"__main__\":\n","    run_svm()"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training records: 1561\n","Number of testing records: 424\n","Accuracy on the test set: 0.9788\n","Support vectors for each class: [14 14]\n","Total number of support vectors: 28\n"]}]},{"cell_type":"markdown","metadata":{"id":"8A2nEnycAhQt"},"source":["## (b)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fwZEu-wNv1SE","executionInfo":{"status":"ok","timestamp":1633365497389,"user_tz":-330,"elapsed":918,"user":{"displayName":"SOUMI CHAKRABORTY","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09195013844947693927"}},"outputId":"9002da2c-408a-48ca-8d22-f4f680f4d5de"},"source":["import csv\n","import numpy as np\n","from sklearn import svm\n","\n","# Enter You Name Here\n","myname = \"Soumi-Chakraborty\"\n","\n","def run_svm(samples):\n","  print(\"Samples:\", samples)\n","\n","  # Load data set\n","  # data_set_path_train = \"/content/drive/MyDrive/Acad_Stuff/Course Work/Semester 5/FoML/Ass2/features.train.txt\"\n","  # data_set_path_test = \"/content/drive/MyDrive/Acad_Stuff/Course Work/Semester 5/FoML/Ass2/features.test.txt\"\n","\n","  data_set_path_train = \"http://www.amlbook.com/data/zip/features.train\"\n","  data_set_path_test = \"http://www.amlbook.com/data/zip/features.test\"\n","  \n","  \n","  # choose only those rows with labels == 1 or 5\n","  # train set\n","  train_data = np.loadtxt(data_set_path_train)\n","  ones = np.where(train_data[:, 0] == 1)\n","  fives = np.where(train_data[:, 0] == 5)\n","  labels = np.append(ones, fives , axis=1)\n","  labels = np.sort(labels)\n","  train_data = (train_data[labels])[0][0:samples, :]\n","  print(\"Number of training records: %d\" % len(train_data))\n","\n","  # test set\n","  test_data = np.loadtxt(data_set_path_test)\n","  ones = np.where(test_data[:, 0] == 1)\n","  fives = np.where(test_data[:, 0] == 5)\n","  labels = np.append(ones, fives , axis=1)\n","  labels = np.sort(labels)\n","  test_data = (test_data[labels])[0]\n","  print(\"Number of testing records: %d\" % len(test_data))\n","\n","  # training the classifier\n","  X = train_data[:, 1:] # all rows, all columns except the last\n","  y = train_data[:, 0]  # all rows, only the last column\n","  svc = svm.SVC(kernel ='linear')\n","  svc.fit(X, y)\n","\n","  X_test =  test_data[:, 1:] # all rows, all columns except the last\n","  y_test = test_data[:,0]  # all rows, only the last column\n","\n","  # predict results for test set\n","  predictions = svc.predict(X_test)\n","\n","  # compute accuracy\n","  results = predictions == y_test\n","  accuracy = float(np.count_nonzero(results))/float(len(results))\n","  print(\"Accuracy on the test set: %.4f\" % accuracy)    \n","\n","  # number of support vectors\n","  sv_count = svc.n_support_\n","  # print(\"Support vectors for each class:\", sv_count)\n","  print(\"Total number of support vectors:\", sv_count.sum())  \n","  print()\n","\n","if __name__ == \"__main__\":\n","  \n","  sample_count = [50, 100, 200, 800]\n","  for sample in sample_count:\n","    run_svm(sample)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Samples: 50\n","Number of training records: 50\n","Number of testing records: 424\n","Accuracy on the test set: 0.9811\n","Total number of support vectors: 2\n","\n","Samples: 100\n","Number of training records: 100\n","Number of testing records: 424\n","Accuracy on the test set: 0.9811\n","Total number of support vectors: 4\n","\n","Samples: 200\n","Number of training records: 200\n","Number of testing records: 424\n","Accuracy on the test set: 0.9811\n","Total number of support vectors: 8\n","\n","Samples: 800\n","Number of training records: 800\n","Number of testing records: 424\n","Accuracy on the test set: 0.9811\n","Total number of support vectors: 14\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"Be0quT81K3XJ"},"source":["## (c)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mh9Uu0kRK1iu","executionInfo":{"status":"ok","timestamp":1633369663291,"user_tz":-330,"elapsed":2221,"user":{"displayName":"SOUMI CHAKRABORTY","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09195013844947693927"}},"outputId":"8eae2b2d-dc81-4441-a1ad-a4704b7e481f"},"source":["import csv\n","import numpy as np\n","from sklearn import svm\n","\n","# Enter You Name Here\n","myname = \"Soumi-Chakraborty\"\n","\n","def run_svm(C, Q, errorType='test'):\n","  print(\"Q =\", Q)\n","\n","  # Load data set\n","  # data_set_path_train = \"/content/drive/MyDrive/Acad_Stuff/Course Work/Semester 5/FoML/Ass2/features.train.txt\"\n","  # data_set_path_test = \"/content/drive/MyDrive/Acad_Stuff/Course Work/Semester 5/FoML/Ass2/features.test.txt\"\n","\n","  data_set_path_train = \"http://www.amlbook.com/data/zip/features.train\"\n","  data_set_path_test = \"http://www.amlbook.com/data/zip/features.test\"\n","  \n","  \n","  # choose only those rows with labels == 1 or 5\n","  # train set\n","  train_data = np.loadtxt(data_set_path_train)\n","  ones = np.where(train_data[:, 0] == 1)\n","  fives = np.where(train_data[:, 0] == 5)\n","  labels = np.append(ones, fives , axis=1)\n","  labels = np.sort(labels)\n","  train_data = (train_data[labels])[0]\n","\n","  # test set\n","  test_data = np.loadtxt(data_set_path_test)\n","  ones = np.where(test_data[:, 0] == 1)\n","  fives = np.where(test_data[:, 0] == 5)\n","  labels = np.append(ones, fives , axis=1)\n","  labels = np.sort(labels)\n","  test_data = (test_data[labels])[0]\n","\n","  # training the classifier\n","  X = train_data[:, 1:] # all rows, all columns except the last\n","  y = train_data[:, 0]  # all rows, only the last column\n","  svc = svm.SVC(kernel='poly', degree=Q, coef0=1, gamma=1, C=C)\n","  svc.fit(X, y)\n","\n","  X_test =  test_data[:, 1:] # all rows, all columns except the last\n","  y_test = test_data[:,0]  # all rows, only the last column\n","\n","  # predict results for test set and training set\n","  if errorType == 'Test':\n","    predictions = svc.predict(X_test)\n","    y_check = y_test\n","  elif errorType == 'Train':\n","    predictions = svc.predict(X)\n","    y_check = y\n","\n","  # error\n","  results = predictions == y_check\n","  accuracy = float(np.count_nonzero(results))/float(len(results))\n","  error = 1 - accuracy\n","  print(str(errorType), \"error: %.4f\" % error)    \n","\n","  # number of support vectors\n","  sv_count = svc.n_support_\n","  print(\"Support vectors:\", sv_count.sum())  \n","  print()\n","\n","\n","if __name__ == \"__main__\":\n","  \n","  print(\"Part i.\")\n","  run_svm(C=0.0001, Q=2, errorType='Train')\n","  run_svm(C=0.0001, Q=5, errorType='Train')\n","\n","  print(\"Part ii.\")\n","  run_svm(C=0.001, Q=2, errorType='Train')\n","  run_svm(C=0.001, Q=5, errorType='Train')\n","\n","  print(\"Part iii.\")\n","  run_svm(C=0.01, Q=2, errorType='Train')\n","  run_svm(C=0.01, Q=5, errorType='Train')\n","\n","  print(\"Part iv.\")\n","  run_svm(C=1, Q=2, errorType='Test')\n","  run_svm(C=1, Q=5, errorType='Test')"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Part i.\n","Q = 2\n","Train error: 0.0090\n","Support vectors: 236\n","\n","Q = 5\n","Train error: 0.0045\n","Support vectors: 26\n","\n","Part ii.\n","Q = 2\n","Train error: 0.0045\n","Support vectors: 76\n","\n","Q = 5\n","Train error: 0.0045\n","Support vectors: 25\n","\n","Part iii.\n","Q = 2\n","Train error: 0.0045\n","Support vectors: 34\n","\n","Q = 5\n","Train error: 0.0038\n","Support vectors: 23\n","\n","Part iv.\n","Q = 2\n","Test error: 0.0189\n","Support vectors: 24\n","\n","Q = 5\n","Test error: 0.0212\n","Support vectors: 21\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"oJztP8HB6-_U"},"source":["i. False\\\n","ii. True\\\n","iii. False\\\n","iv. False\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eCQLbXAllW38"},"source":["## (d)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lba7m1WylYH6","executionInfo":{"status":"ok","timestamp":1633365872905,"user_tz":-330,"elapsed":934,"user":{"displayName":"SOUMI CHAKRABORTY","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09195013844947693927"}},"outputId":"b3060d45-f924-4dad-9fd8-0ef26af83dc5"},"source":["import csv\n","import numpy as np\n","from sklearn import svm\n","\n","# Enter You Name Here\n","myname = \"Soumi-Chakraborty\"\n","\n","def run_svm(C):\n","  print(\"C =\", C)\n","\n","  # Load data set\n","  # data_set_path_train = \"/content/drive/MyDrive/Acad_Stuff/Course Work/Semester 5/FoML/Ass2/features.train.txt\"\n","  # data_set_path_test = \"/content/drive/MyDrive/Acad_Stuff/Course Work/Semester 5/FoML/Ass2/features.test.txt\"\n","\n","  data_set_path_train = \"http://www.amlbook.com/data/zip/features.train\"\n","  data_set_path_test = \"http://www.amlbook.com/data/zip/features.test\"\n","  \n","  \n","  # choose only those rows with labels == 1 or 5\n","  # train set\n","  train_data = np.loadtxt(data_set_path_train)\n","  ones = np.where(train_data[:, 0] == 1)\n","  fives = np.where(train_data[:, 0] == 5)\n","  labels = np.append(ones, fives , axis=1)\n","  labels = np.sort(labels)\n","  train_data = (train_data[labels])[0]\n","\n","  # test set\n","  test_data = np.loadtxt(data_set_path_test)\n","  ones = np.where(test_data[:, 0] == 1)\n","  fives = np.where(test_data[:, 0] == 5)\n","  labels = np.append(ones, fives , axis=1)\n","  labels = np.sort(labels)\n","  test_data = (test_data[labels])[0]\n","\n","  # training the classifier\n","  X = train_data[:, 1:] # all rows, all columns except the last\n","  y = train_data[:, 0]  # all rows, only the last column\n","  svc = svm.SVC(kernel='rbf', gamma=1, C=C)\n","  svc.fit(X, y)\n","\n","  X_test =  test_data[:, 1:] # all rows, all columns except the last\n","  y_test = test_data[:,0]  # all rows, only the last column\n","\n","  # predict results for test set and training set\n","  predictions_test = svc.predict(X_test)\n","  predictions_train = svc.predict(X)\n","\n","  # test error\n","  results = predictions_test == y_test\n","  accuracy = float(np.count_nonzero(results))/float(len(results))\n","  error = 1 - accuracy\n","  print(\"Test error: %.4f\" % error)\n","\n","  # train error\n","  results = predictions_train == y\n","  accuracy = float(np.count_nonzero(results))/float(len(results))\n","  error = 1 - accuracy\n","  print(\"Train error: %.4f\" % error)\n","\n","  print()\n","\n","\n","if __name__ == \"__main__\":\n","  \n","  cVal = [0.01, 1, 100, 10000, 1000000]\n","  for C in cVal:\n","    run_svm(C)"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["C = 0.01\n","Test error: 0.0236\n","Train error: 0.0038\n","\n","C = 1\n","Test error: 0.0212\n","Train error: 0.0045\n","\n","C = 100\n","Test error: 0.0189\n","Train error: 0.0032\n","\n","C = 10000\n","Test error: 0.0236\n","Train error: 0.0026\n","\n","C = 1000000\n","Test error: 0.0236\n","Train error: 0.0006\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"thj2YUkKLAth"},"source":["Lowest test error: 1.89%\\\n","Given by C = 100\n","\n","Lowest train error: 0.06%\\\n","Given by C = 1000000"]},{"cell_type":"markdown","metadata":{"id":"mnJCb-AGMmyK"},"source":["# Question 5"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TYXOTo5DhvWr","executionInfo":{"status":"ok","timestamp":1633524427088,"user_tz":-330,"elapsed":26280,"user":{"displayName":"SOUMI CHAKRABORTY","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09195013844947693927"}},"outputId":"20bd71e3-8421-4c0d-d46d-c90b44d3135a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"a4x0mfEzMwYE"},"source":["## (a)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LkEECLM5JMq1","executionInfo":{"status":"ok","timestamp":1633544202546,"user_tz":-330,"elapsed":135243,"user":{"displayName":"SOUMI CHAKRABORTY","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09195013844947693927"}},"outputId":"d2c7efb1-a8e6-40de-fe5c-3be05b239d8c"},"source":["import csv\n","import numpy as np\n","from sklearn import svm\n","import sys\n","\n","# Enter You Name Here\n","myname = \"Soumi-Chakraborty\"\n","\n","def run_svm():\n","\n","    # Load data set\n","    train_path = \"/content/drive/MyDrive/Acad_Stuff/Course Work/Semester 5/FoML/Ass2/gisette_train.data\"\n","    train_labels_path = \"/content/drive/MyDrive/Acad_Stuff/Course Work/Semester 5/FoML/Ass2/gisette_train.labels\"\n","    valid_path = \"/content/drive/MyDrive/Acad_Stuff/Course Work/Semester 5/FoML/Ass2/gisette_valid.data\"\n","    valid_labels_path = \"/content/drive/MyDrive/Acad_Stuff/Course Work/Semester 5/FoML/Ass2/gisette_valid.labels\"\n","\n","    # train_path = \"gisette_train.data\"\n","    # train_labels_path = \"gisette_train.labels\"\n","    # valid_path = \"gisette_valid.data\"\n","    # valid_labels_path = \"gisette_valid.labels\"\n","\n","    # train set\n","    X = np.loadtxt(train_path)\n","    y = np.loadtxt(train_labels_path)\n","    print(\"Number of training records: %d\" % len(X))\n","\n","    # test set\n","    X_test = np.loadtxt(valid_path)\n","    y_test = np.loadtxt(valid_labels_path)\n","    print(\"Number of test records: %d\" % len(X_test))\n","    \n","    # training the classifier\n","    svc = svm.SVC(kernel ='linear')\n","    svc.fit(X, y)\n","\n","    # predict results for test set and training set\n","    predictions_test = svc.predict(X_test)\n","    predictions_train = svc.predict(X)\n","\n","    # test error\n","    results = predictions_test == y_test\n","    accuracy = float(np.count_nonzero(results))/float(len(results))\n","    error = 1 - accuracy\n","    print(\"Test error: %.4f\" % error)\n","    \n","\n","    # train error\n","    results = predictions_train == y\n","    accuracy = float(np.count_nonzero(results))/float(len(results))\n","    error = 1 - accuracy\n","    print(\"Train error: %.4f\" % error)\n","    \n","    # number of support vectors\n","    sv_count = svc.n_support_\n","    print(\"Total number of support vectors:\", sv_count.sum())\n","\n","    \n","\n","\n","if __name__ == \"__main__\":\n","    run_svm()"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training records: 6000\n","Number of test records: 1000\n","Test error: 0.0240\n","Train error: 0.0000\n","Total number of support vectors: 1084\n"]}]},{"cell_type":"markdown","metadata":{"id":"2BS1vwNWS2S6"},"source":["## (b)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RDAxuabVCyUR","executionInfo":{"status":"ok","timestamp":1633545015695,"user_tz":-330,"elapsed":811837,"user":{"displayName":"SOUMI CHAKRABORTY","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09195013844947693927"}},"outputId":"1c7b70ad-bd55-44d2-9b70-0ebe8ee2419a"},"source":["import csv\n","import numpy as np\n","from sklearn import svm\n","import sys\n","\n","# Enter You Name Here\n","myname = \"Soumi-Chakraborty\"\n","\n","\n","def run_svm(kernel):\n","  print(\"Kernel type:\", kernel)\n","\n","\n","  # Load data set\n","  train_path = \"/content/drive/MyDrive/Acad_Stuff/Course Work/Semester 5/FoML/Ass2/gisette_train.data\"\n","  train_labels_path = \"/content/drive/MyDrive/Acad_Stuff/Course Work/Semester 5/FoML/Ass2/gisette_train.labels\"\n","  valid_path = \"/content/drive/MyDrive/Acad_Stuff/Course Work/Semester 5/FoML/Ass2/gisette_valid.data\"\n","  valid_labels_path = \"/content/drive/MyDrive/Acad_Stuff/Course Work/Semester 5/FoML/Ass2/gisette_valid.labels\"\n","\n","  # train_path = \"gisette_train.data\"\n","  # train_labels_path = \"gisette_train.labels\"\n","  # valid_path = \"gisette_valid.data\"\n","  # valid_labels_path = \"gisette_valid.labels\"\n","  \n","  # train set\n","  X = np.loadtxt(train_path)\n","  y = np.loadtxt(train_labels_path)\n","  print(\"Number of training records: %d\" % len(X))\n","\n","  # test set\n","  X_test = np.loadtxt(valid_path)\n","  y_test = np.loadtxt(valid_labels_path)\n","  print(\"Number of test records: %d\" % len(X_test))\n","  \n","  # training the classifier\n","  if kernel == 'rbf':\n","    svc = svm.SVC(kernel ='rbf', gamma=0.001)\n","    svc.fit(X, y)\n","  elif kernel == 'poly':\n","    # svc = svm.SVC(kernel ='poly', gamma=1, degree=2, coef0=1)\n","    svc = svm.SVC(kernel ='poly', degree=2, coef0=1)\n","    svc.fit(X, y)\n","  else:\n","    svc = svm.SVC(kernel ='linear')\n","    svc.fit(X, y)\n","\n","  # predict results for test set and training set\n","  predictions_test = svc.predict(X_test)\n","  predictions_train = svc.predict(X)\n","\n","  # test error\n","  results = predictions_test == y_test\n","  accuracy = float(np.count_nonzero(results))/float(len(results))\n","  error = 1 - accuracy\n","  print(\"Test error: %.4f\" % error)\n","\n","\n","  # train error\n","  results = predictions_train == y\n","  accuracy = float(np.count_nonzero(results))/float(len(results))\n","  error = 1 - accuracy\n","  print(\"Train error: %.4f\" % error)\n","\n","  # number of support vectors\n","  sv_count = svc.n_support_\n","  print(\"Total number of support vectors:\", sv_count.sum())\n","  print()\n","\n","    \n","\n","\n","if __name__ == \"__main__\":\n","    run_svm('rbf')\n","    run_svm('poly')\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Kernel type: rbf\n","Number of training records: 6000\n","Number of test records: 1000\n","Test error: 0.5000\n","Train error: 0.0000\n","Total number of support vectors: 6000\n","\n","Kernel type: poly\n","Number of training records: 6000\n","Number of test records: 1000\n","Test error: 0.0200\n","Train error: 0.0005\n","Total number of support vectors: 1332\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"A8aAjjOU1ROB"},"source":["The rbf kernel reports the lowest training error since it's 0 whereas the polynomial kernel reports a training error of 0.0005."]}]}